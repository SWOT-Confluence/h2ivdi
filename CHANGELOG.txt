Version 0.5c
- Change run_hivdi.py to run_h2ivdi.py for Confluence
- Change hivdi to h2ivdi in docker images tags
- Compiliant with SWORD v11
- Handles new organization of the NetCDF Sword Of Science files (v0.0)

Version 0.5b
- Correct a minor bug when number of observations is less than 2.
- Handles new organization of the NetCDF Sword Of Science files

Version 0.5
- Cases with non valid data now produce empty estimates, i.e. NaN values for parameters and discharge timeseries.
- Values of array 'nt' in output files exactly match values of array 'nt' in SWOT observations files.
- Cases with less nodes for a reach in SWOT files than in SWORD dataset are now handled.

Version 0.4b
- Handles SWOT observations with numerous NaN data.
- Modification of the arguments with new option -reachjson to change the default filename. 

Version 0.4
- Add support for SWORD netcdf files.
- Implement new surrogate model.
- Add the option -chain for choosing between classic and surrogate models.

Version 0.3
- Split the docker image in two images (base and aws).
- Removed the ENTRYPOINT in base image Dockerfile.
- Modification of the output files format. Now one netCDF file per reach is produced.
- Add parameter 'dx' in the run_hivdi.py script.
- Add environment variable VRT_ITERATIONS_COUNT to enforce the number of VDA iterations in the aws Dockerfile.
- Virtual topology is implemented (for the purpose of benchmarks on synthetic data files w/o topology).

Version 0.2
- Use of ENTRYPOINT in the Dockerfile to reproduce the way of lauching other algorithms (geoBAM, MetroMan)
- Add the option -window to select a subset of time occurences

Version 0.1
Initial docker image
